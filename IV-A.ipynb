{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b493e9",
   "metadata": {},
   "source": [
    "# Section IV-A — Toy stationary renewable generation\n",
    "Key features vs IV-B (non-stationary case):\n",
    "- Constant mean-reversion level $m_k \\equiv m$ (no DA forecast input).\n",
    "- Constant dispatch target $M_k \\equiv M$ for all time steps.\n",
    "- Stationary additive-noise dynamics: $$X_{k+1}=X_k+\\alpha(m-X_k)\\Delta t+\\sigma\\,Z_k\\sqrt{\\Delta t}.$$\n",
    "- Time-homogeneous regression design $\\mathcal{D}$: same LHS state domain used at every step.\n",
    "\n",
    "（Based on Thiha Aung & Mike Ludkovski, IEEE CDC 2024）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a77f1-7dbe-40a1-bca8-aac04084fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9dddd-078a-4951-8864-33f8f6a13b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Parameters \n",
    "# Model parameters\n",
    "Delta_t = 0.25          # 15-minute intervals\n",
    "n_steps = 96            # 24 hours → 96 steps\n",
    "\n",
    "# Wind power parameters\n",
    "alpha = 1.0\n",
    "sigma = 1.0\n",
    "m_k = 5.0               # constant mean reversion level\n",
    "Mk = 5.0               # constant dispatch target\n",
    "\n",
    "# SoC parameters\n",
    "Icap = 8.0             # MWh\n",
    "SoC_min = 0.05\n",
    "SoC_max = 0.95\n",
    "eta = 0.9\n",
    "Bmax = 2.0\n",
    "Bmin = -2.0\n",
    "\n",
    "# Cost parameters\n",
    "lambda_penalty = 50.0\n",
    "\n",
    "# Initial condition\n",
    "I0 = 0.1 * Icap\n",
    "\n",
    "# LHS design parameters\n",
    "X_min_design = 0.0\n",
    "X_max_design = 10.0\n",
    "I_min_design = 0.0\n",
    "I_max_design = Icap\n",
    "Nloc = 600             # number of unique sites (paper uses 600 - reduce for speed)\n",
    "Nrep = 50              # replications (paper uses 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab90854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper functions\n",
    "# Wind power dynamics\n",
    "def next_X(X_current, m_k, alpha, sigma, Delta_t):\n",
    "    noise = np.random.normal(size=np.shape(X_current), scale=np.sqrt(Delta_t))\n",
    "    return X_current + alpha * (m_k - X_current) * Delta_t + sigma * noise\n",
    "\n",
    "# SoC dynamics\n",
    "def next_I(I_current, B, Delta_t, eta):\n",
    "    # Handle scalar case for simulation\n",
    "    if np.isscalar(B):\n",
    "        if B >= 0:\n",
    "            return I_current + eta * B * Delta_t\n",
    "        else:\n",
    "            return I_current + B * Delta_t / eta\n",
    "    # Vector case for simulation\n",
    "    else:\n",
    "        result = np.empty_like(np.array(B, dtype=float))\n",
    "        mask = np.array(B) >= 0\n",
    "        result[mask] = I_current[mask] + eta * B[mask] * Delta_t\n",
    "        result[~mask] = I_current[~mask] + B[~mask] * Delta_t / eta\n",
    "        return result\n",
    "\n",
    "# Terminal cost\n",
    "def terminal_penalty(IT):\n",
    "    return lambda_penalty * max(0.1 * Icap - IT, 0)\n",
    "\n",
    "# Get bounds on B given I\n",
    "def get_bounds_approx(I_approx, Delta_t, eta, Icap, SoC_min, SoC_max, Bmin, Bmax):\n",
    "    lower = max(Bmin, eta * (SoC_min * Icap - I_approx) / Delta_t)\n",
    "    upper = min(Bmax, (SoC_max * Icap - I_approx) / (eta * Delta_t))\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9362ed9-e5a0-45fc-a43e-afb3d8e1f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Latin Hypercube Design (same for all steps in stationary case)\n",
    "# Generate LHS design\n",
    "def latin_hypercube(n_samples, dim, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    cut = np.linspace(0, 1, n_samples + 1)\n",
    "    \n",
    "    u = np.zeros((n_samples, dim))\n",
    "    for j in range(dim):\n",
    "        # Random point inside each interval for dimension j\n",
    "        u[:, j] = rng.uniform(cut[:-1], cut[1:])\n",
    "        # Randomly permute\n",
    "        rng.shuffle(u[:, j])   \n",
    "    return u\n",
    "\n",
    "# Scale LHS to desired bounds\n",
    "def scale_lhs(lhs, lower_bounds, upper_bounds):\n",
    "    lower_bounds = np.asarray(lower_bounds)\n",
    "    upper_bounds = np.asarray(upper_bounds)\n",
    "    return lower_bounds + lhs * (upper_bounds - lower_bounds)\n",
    "\n",
    "# Generate and scale design\n",
    "design_base = latin_hypercube(Nloc, 2, seed=42)\n",
    "X_I_base = scale_lhs(design_base,\n",
    "                     [X_min_design, I_min_design],\n",
    "                     [X_max_design, I_max_design])\n",
    "X_base = X_I_base[:, 0]\n",
    "I_next_base = X_I_base[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: RMC Backward Loop\n",
    "\n",
    "# ---------- Options ----------\n",
    "resample_design_each_step = False  # keep stationary LHS by default\n",
    "use_surrogate_for_pathwise_B = False  # we won't use surrogate for pathwise B here\n",
    "n_restarts_control = 10 # Hyperparameter restarts for control GP\n",
    "n_restarts_value = 10 # Hyperparameter restarts for value GP\n",
    "opt_options = {'ftol': 1e-9, 'maxiter': 200}   # options for minimize (L-BFGS-B)\n",
    "# -----------------------------\n",
    "\n",
    "# pre-alloc\n",
    "control_gps = [None] * n_steps\n",
    "value_gps   = [None] * n_steps\n",
    "\n",
    "def terminal_penalty_array(it_array):\n",
    "    return np.array([terminal_penalty(float(x)) for x in np.atleast_1d(it_array)])\n",
    "\n",
    "# Total number of replicates across all design points\n",
    "N = Nloc * Nrep\n",
    "\n",
    "# Backward induction over time steps\n",
    "for t in range(n_steps - 1, -1, -1):\n",
    "    print(f\"Backward step t = {t} / {n_steps - 1}\")\n",
    "\n",
    "    # Generate design D_t\n",
    "    X_I_design = X_I_base.copy()  # shape (Nloc, 2)\n",
    "    X_t_loc = X_I_design[:, 0]   # X_t^i for i=0..Nloc-1\n",
    "    I_t_loc = X_I_design[:, 1]   # I_t^i\n",
    "\n",
    "    # Replicate each design location Nrep times to form pathwise simulation inputs\n",
    "    # We'll create arrays of length N = Nloc * Nrep where replicates for location i occupy indices i*Nrep:(i+1)*Nrep\n",
    "    X_current = np.repeat(X_t_loc, Nrep)   # shape (N,)\n",
    "    I_current = np.repeat(I_t_loc, Nrep)   # shape (N,)\n",
    "\n",
    "    # Simulate one-step forward X_t -> X_{t+1}\n",
    "    # This will draw random normals inside next_X, producing pathwise X_next for each replicate\n",
    "    X_next = next_X(X_current, m_k, alpha, sigma, Delta_t)  # shape (N,)\n",
    "\n",
    "    # Compute an optimal scalar b_i for each design location i\n",
    "    B_opt_per_loc = np.zeros(Nloc, dtype=float)\n",
    "\n",
    "    # For each design location i, prepare indices and replicate data\n",
    "    for i in range(Nloc):\n",
    "        # replicate index range\n",
    "        start = i * Nrep\n",
    "        end = start + Nrep\n",
    "\n",
    "        # data for this design location's replicates\n",
    "        X_cur_rep = X_current[start:end]   # shape (Nrep,)\n",
    "        X_next_rep = X_next[start:end]     # shape (Nrep,)\n",
    "        I_cur_rep = I_current[start:end]   # shape (Nrep,) -- all equal to I_t_loc[i] typically\n",
    "\n",
    "        # compute feasible bounds for this design location (using I at time t)\n",
    "        lower_i, upper_i = get_bounds_approx(I_t_loc[i], Delta_t, eta, Icap, SoC_min, SoC_max, Bmin, Bmax)\n",
    "\n",
    "        # if degenerate bounds, simply set to midpoint and skip optimization\n",
    "        if lower_i >= upper_i:\n",
    "            B_opt_per_loc[i] = 0.5 * (lower_i + upper_i)\n",
    "            continue\n",
    "\n",
    "        # Define objective for location i: average over replicates j\n",
    "        # Note: we DO NOT enforce bounds inside the optimizer; we clip AFTER optimization\n",
    "        def obj_scalar(b_array):\n",
    "            # minimize expects array-like, but we just optimize scalar, so convert\n",
    "            b = float(np.atleast_1d(b_array)[0])\n",
    "\n",
    "            # immediate losses for each replicate j (L2 loss)\n",
    "            immediate = (X_cur_rep - b - Mk) ** 2  # shape (Nrep,)\n",
    "\n",
    "            # next inventories for each replicate given this single b\n",
    "            I_next_rep = next_I(I_cur_rep, b, Delta_t, eta)  # shape (Nrep,) vectorized\n",
    "\n",
    "            # continuation value for each replicate\n",
    "            if t == n_steps - 1:\n",
    "                # last decision step: continuation value is terminal penalty\n",
    "                cont_rep = terminal_penalty_array(I_next_rep)\n",
    "            else:\n",
    "                # general case: use learned value function at t+1\n",
    "                cont_rep = value_gps[t + 1].predict(np.column_stack((X_next_rep, I_next_rep))).flatten()\n",
    "\n",
    "            # average pathwise cost across the Nrep replicates (this is the objective for location i)\n",
    "            mean_cost = np.mean(immediate + cont_rep)\n",
    "            return mean_cost\n",
    "\n",
    "        # initial guess: midpoint of feasible interval\n",
    "        x0 = np.array([0.5 * (lower_i + upper_i)])\n",
    "\n",
    "        # Run scalar optimization using L-BFGS-B (no bounds passed)\n",
    "        res = minimize(obj_scalar, x0=x0, method='L-BFGS-B', options=opt_options)\n",
    "        b_hat = float(res.x[0])\n",
    "\n",
    "        # Clip the result to feasible interval AFTER optimization (paper's approach)\n",
    "        b_clipped = np.clip(b_hat, lower_i, upper_i)\n",
    "        B_opt_per_loc[i] = b_clipped\n",
    "\n",
    "    # Now we have one optimized control per design location (Nloc). Expand it to all replicates:\n",
    "    B_pathwise = np.repeat(B_opt_per_loc, Nrep)  # shape (N,)\n",
    "\n",
    "    # Compute pathwise immediate loss, next inventory and continuation \n",
    "    I_next_all = next_I(I_current, B_pathwise, Delta_t, eta)  # vectorized shape (N,)\n",
    "    loss_all = (X_current - B_pathwise - Mk) ** 2\n",
    "\n",
    "    if t == n_steps - 1:\n",
    "        cont_all = terminal_penalty_array(I_next_all)\n",
    "    else:\n",
    "        cont_all = value_gps[t + 1].predict(np.column_stack((X_next, I_next_all))).flatten()\n",
    "\n",
    "    v_all = loss_all + cont_all  # pathwise costs (N,)\n",
    "\n",
    "    # Average over replicates -> regression targets of length Nloc \n",
    "    B_avg = B_pathwise.reshape(Nloc, Nrep).mean(axis=1)   # equals B_opt_per_loc basically\n",
    "    v_avg = v_all.reshape(Nloc, Nrep).mean(axis=1)\n",
    "\n",
    "    # Fit control GP (Matérn 3/2) \n",
    "    control_kernel = Matern(length_scale=1.0, nu=1.5)\n",
    "    control_gp = GaussianProcessRegressor(kernel=control_kernel,\n",
    "                                          n_restarts_optimizer=n_restarts_control,\n",
    "                                          random_state=42)\n",
    "    control_gp.fit(X_I_design, B_avg)   # inputs shape (Nloc,2)\n",
    "    control_gps[t] = control_gp\n",
    "\n",
    "    #  Fit value GP (Matérn 5/2) at EVERY decision step \n",
    "    value_kernel = Matern(length_scale=[1.0, 1.0], nu=2.5)\n",
    "    value_gp = GaussianProcessRegressor(kernel=value_kernel,\n",
    "                                        n_restarts_optimizer=n_restarts_value,\n",
    "                                        random_state=42)\n",
    "    value_gp.fit(X_I_design, v_avg)\n",
    "    value_gps[t] = value_gp\n",
    "\n",
    "    print(f\"Completed t={t}: optimized {Nloc} locations, fitted control GP and value GP\")\n",
    "\n",
    "print(\"Backward pass completed: control_gps and value_gps ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f32dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Simulate paths with learned policy (out-of-sample evaluation) - Monte carlo simulation\n",
    "def simulate_path(X_start=5.0, I_start=I0, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X_path = [X_start]\n",
    "    I_path = [I_start]\n",
    "    B_path = []\n",
    "    O_path = []\n",
    "    \n",
    "    X = float(X_start)\n",
    "    I = float(I_start)\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        # Predict raw control from GP\n",
    "        B_raw = float(control_gps[step].predict([[X, I]])[0])\n",
    "        # Enforce feasible control bounds implied by SoC constraints\n",
    "        lower, upper = get_bounds_approx(I, Delta_t, eta, Icap, SoC_min, SoC_max, Bmin, Bmax)\n",
    "        B = float(np.clip(B_raw, lower, upper))\n",
    "        O = X - B\n",
    "        \n",
    "        B_path.append(B)\n",
    "        O_path.append(O)\n",
    "        \n",
    "        X = next_X(X, m_k, alpha, sigma, Delta_t)\n",
    "        I = next_I(I, B, Delta_t, eta)\n",
    "        # numerical safety (should already be satisfied if B is clipped)\n",
    "        I = float(np.clip(I, SoC_min * Icap, SoC_max * Icap))\n",
    "        \n",
    "        X_path.append(X)\n",
    "        I_path.append(I)\n",
    "    \n",
    "    return (np.array(X_path), np.array(I_path), np.array(B_path), np.array(O_path))\n",
    "\n",
    "# Example: 5 paths\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12,10))\n",
    "for i in range(5):\n",
    "    X_p, I_p, B_p, O_p = simulate_path(seed=i)\n",
    "    axes[0].plot(X_p, alpha=0.7, label=f'Path {i+1}' if i<1 else None)\n",
    "    axes[1].plot(B_p, alpha=0.7)\n",
    "    axes[2].plot(I_p, alpha=0.7)\n",
    "    axes[3].plot(O_p, alpha=0.7)\n",
    "\n",
    "axes[0].set(title='Wind Generation Xk', ylabel='MW')\n",
    "axes[1].set(title='Battery Control Bk', ylabel='MW')\n",
    "axes[2].set(title='SoC Ik', ylabel='MWh')\n",
    "axes[3].set(title='Firmed Output Ok', ylabel='MW', xlabel='Time step (15 min)')\n",
    "axes[0].axhline(m_k, color='k', linestyle='--')\n",
    "axes[3].axhline(Mk, color='k', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f78b9f-08d1-4496-ae75-7380645ba545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Compute Monte Carlo value function estimate (as in Eq. 16)\n",
    "M = 2000\n",
    "costs = np.zeros(M)\n",
    "\n",
    "for m in range(M):\n",
    "    X_p, I_p, B_p, O_p = simulate_path(seed=m+1000)\n",
    "    cost = np.sum((O_p - Mk)**2) + terminal_penalty(I_p[-1])\n",
    "    costs[m] = cost\n",
    "\n",
    "value_estimate = np.mean(costs)\n",
    "print(f\"Estimated value function V(0, X0=5, I0={I0:.2f}): {value_estimate:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9828b80-9cac-4f38-bea4-bd4769e9dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot optimal control map at t=0 (like Figure 3 left)\n",
    "x_grid, i_grid = np.mgrid[X_min_design:X_max_design:200j, I_min_design:I_max_design:200j]\n",
    "positions = np.vstack([x_grid.ravel(), i_grid.ravel()]).T\n",
    "B_pred = control_gps[0].predict(positions).reshape(x_grid.shape)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.contourf(x_grid, i_grid, B_pred, levels=100, cmap='RdBu_r')\n",
    "plt.colorbar(label='Optimal B (MW)')\n",
    "plt.contour(x_grid, i_grid, B_pred, levels=[0], colors='white', linestyles='--')\n",
    "plt.xlabel('Wind Power X (MW)')\n",
    "plt.ylabel('SoC I (MWh)')\n",
    "plt.title('Optimal Control Policy at t=0 (L2 criterion)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
