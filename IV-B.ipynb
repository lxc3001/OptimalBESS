{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98cd89a0",
   "metadata": {},
   "source": [
    "# Section IV-B — Non-stationary renewable generation\n",
    "\n",
    "Key differences vs IV-A (toy stationary case):\n",
    "- Time-varying mean reversion profile $m_k$ derived from DA forecasts (hourly → 15-min via cubic splines).\n",
    "- Nonnegative, state-dependent-volatility dynamics: $$X_{k+1}=|X_k+\\alpha(m_k-X_k)\\Delta t+\\sigma\\sqrt{X_k}\\,Z_k\\sqrt{\\Delta t}|.$$\n",
    "- Step-dependent adaptive regression designs $\\mathcal{D}_k$ built from pilot-simulated $E[X_k]$ and $\\mathrm{StDev}[X_k]$.\n",
    "- Two target modes $M_k$: (i) $M_k=m_k=E[X_k]$ and (ii) piecewise-linear $M_k$ from the original hourly DA forecast.\n",
    "\n",
    "（Based on Thiha Aung & Mike Ludkovski, IEEE CDC 2024）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a77f1-7dbe-40a1-bca8-aac04084fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: IV-B parameters (Table I) + utilities\n",
    "import pandas as pd\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# ==== Lightweight LHS utilities (replacement for scipy.qmc) ====\n",
    "def latin_hypercube(n_samples: int, dim: int, seed: int | None = None) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    cut = np.linspace(0, 1, n_samples + 1)\n",
    "    u = np.zeros((n_samples, dim))\n",
    "    for j in range(dim):\n",
    "        u[:, j] = rng.uniform(cut[:-1], cut[1:])\n",
    "        rng.shuffle(u[:, j])\n",
    "    return u\n",
    "\n",
    "def scale_lhs(lhs: np.ndarray, lower_bounds, upper_bounds) -> np.ndarray:\n",
    "    lower_bounds = np.asarray(lower_bounds, dtype=float)\n",
    "    upper_bounds = np.asarray(upper_bounds, dtype=float)\n",
    "    return lower_bounds + lhs * (upper_bounds - lower_bounds)\n",
    "\n",
    "# --- Paper Table I: IV-B ---\n",
    "Delta_t_B = 0.25   # hours (15 minutes)\n",
    "n_steps_B = 96     # 24h / 15min\n",
    "T_hours_B = n_steps_B * Delta_t_B\n",
    "\n",
    "alpha_B = 5.0\n",
    "sigma_B = 1.0\n",
    "\n",
    "Icap_B = 50.0      # MWh\n",
    "I0_B = 0.1 * Icap_B\n",
    "\n",
    "Bmax_B = 10.0      # MW\n",
    "Bmin_B = -10.0    # MW\n",
    "\n",
    "eta_B = 0.90\n",
    "SoC_min_B = 0.05\n",
    "SoC_max_B = 0.95\n",
    "lambda_penalty_B = 50.0\n",
    "\n",
    "# RMC budget (paper uses Nloc=600, Nrep=50; start smaller if needed)\n",
    "Nloc_B = 200\n",
    "Nrep_B = 30\n",
    "\n",
    "# Data file\n",
    "FORECAST_CSV = \"wind_forecast_time_value_raw_mean_2018.csv\"\n",
    "\n",
    "# Choose a day to replicate (paper shows several months; pick any date present in your CSV)\n",
    "DAY_TO_RUN = \"2018-07-15\"  # YYYY-MM-DD\n",
    "TARGET_MODE = \"mean\"       # \"mean\" => Mk = mk ; \"forecast\" => piecewise-linear Mk from hourly forecast\n",
    "\n",
    "# Monte Carlo for pilot stats / confidence bands\n",
    "MC_PATHS_PILOT = 3000   # pilot paths to estimate E[Xk], StDev[Xk]\n",
    "MC_PATHS_BANDS = 1000   # paths for 95% CI bands (can reduce for speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load hourly forecast and build 15-min profiles m_k and M_k\n",
    "def load_hourly_forecast(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Expect columns: forecast_time, forecast_value\n",
    "    if \"forecast_time\" not in df.columns or \"forecast_value\" not in df.columns:\n",
    "        raise ValueError(f\"Expected columns forecast_time, forecast_value; got {list(df.columns)}\")\n",
    "    df[\"forecast_time\"] = pd.to_datetime(df[\"forecast_time\"], utc=True, errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"forecast_time\"]).sort_values(\"forecast_time\")\n",
    "    df[\"forecast_value\"] = pd.to_numeric(df[\"forecast_value\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"forecast_value\"])\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def build_profiles_for_day(df_hourly: pd.DataFrame, day_yyyy_mm_dd: str, Delta_t_hours: float, n_steps: int, target_mode: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      mk: ndarray shape (n_steps,)  (cubic-spline upscaled mean-reversion profile)\n",
    "      Mk: ndarray shape (n_steps,)  (dispatch target profile)\n",
    "      t_hours: ndarray shape (n_steps,) time grid in hours from 0\n",
    "    \"\"\"\n",
    "    day = pd.Timestamp(day_yyyy_mm_dd).tz_localize(\"UTC\")\n",
    "    t0 = day\n",
    "    t1 = day + pd.Timedelta(hours=24)\n",
    "    day_df = df_hourly[(df_hourly[\"forecast_time\"] >= t0) & (df_hourly[\"forecast_time\"] <= t1)].copy()\n",
    "    if day_df.empty or day_df[\"forecast_time\"].nunique() < 5:\n",
    "        raise ValueError(f\"Not enough hourly forecast data for {day_yyyy_mm_dd}. Try a different date.\")\n",
    "\n",
    "    # Build an hourly grid relative to t0\n",
    "    x_hours = ((day_df[\"forecast_time\"] - t0) / pd.Timedelta(hours=1)).to_numpy()\n",
    "    y = day_df[\"forecast_value\"].to_numpy(dtype=float)\n",
    "\n",
    "    # 15-minute grid (0, 0.25, ..., 23.75)\n",
    "    t_hours = np.arange(n_steps, dtype=float) * Delta_t_hours\n",
    "\n",
    "    # Paper: cubic splines for mean-reversion profile mk\n",
    "    cs = CubicSpline(x_hours, y, extrapolate=True)\n",
    "    mk = cs(t_hours)\n",
    "    mk = np.maximum(mk, 0.0)  # generation is nonnegative in IV-B setup\n",
    "\n",
    "    # Targets Mk\n",
    "    if target_mode == \"mean\":\n",
    "        Mk = mk.copy()\n",
    "    elif target_mode == \"forecast\":\n",
    "        # piecewise-linear interpolation of the original hourly forecasts (paper Fig. 5 right panels)\n",
    "        Mk = np.interp(t_hours, x_hours, y)\n",
    "        Mk = np.maximum(Mk, 0.0)\n",
    "    else:\n",
    "        raise ValueError(\"target_mode must be 'mean' or 'forecast'\")\n",
    "\n",
    "    return mk, Mk, t_hours\n",
    "\n",
    "df_hourly = load_hourly_forecast(FORECAST_CSV)\n",
    "mk_B, Mk_B, t_hours_B = build_profiles_for_day(df_hourly, DAY_TO_RUN, Delta_t_B, n_steps_B, TARGET_MODE)\n",
    "\n",
    "print(\"Loaded forecast rows:\", len(df_hourly))\n",
    "print(\"Running day:\", DAY_TO_RUN, \"target_mode=\", TARGET_MODE)\n",
    "print(\"mk_B range:\", float(np.min(mk_B)), \"..\", float(np.max(mk_B)))\n",
    "print(\"Mk_B range:\", float(np.min(Mk_B)), \"..\", float(np.max(Mk_B)))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(t_hours_B, mk_B, label=\"m_k (cubic spline)\")\n",
    "plt.plot(t_hours_B, Mk_B, \"--\", label=\"M_k (target)\")\n",
    "plt.title(\"IV-B profiles (15-min)\")\n",
    "plt.xlabel(\"Hour of day\")\n",
    "plt.ylabel(\"MW\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: IV-B dynamics (paper Eq. 19) + pilot stats for adaptive designs\n",
    "def terminal_penalty_B(IT: float) -> float:\n",
    "    return float(lambda_penalty_B * max(0.1 * Icap_B - IT, 0.0))\n",
    "\n",
    "def terminal_penalty_array_B(it_array):\n",
    "    it_array = np.atleast_1d(it_array).astype(float)\n",
    "    return np.array([terminal_penalty_B(float(x)) for x in it_array])\n",
    "\n",
    "def get_bounds_B(I_approx: float):\n",
    "    lower = max(Bmin_B, eta_B * (SoC_min_B * Icap_B - I_approx) / Delta_t_B)\n",
    "    upper = min(Bmax_B, (SoC_max_B * Icap_B - I_approx) / (eta_B * Delta_t_B))\n",
    "    return lower, upper\n",
    "\n",
    "def next_X_nonstationary(\n",
    "    X_current,\n",
    "    mk_scalar: float,\n",
    "    alpha: float,\n",
    "    sigma: float,\n",
    "    Delta_t: float,\n",
    "    *,\n",
    "    rng: np.random.Generator | None = None,\n",
    "):\n",
    "    \"\"\"Discrete nonstationary square-root process (paper Eq. 19).\n",
    "    If rng is provided, randomness is fully reproducible and isolated from global NumPy state.\n",
    "    \"\"\"\n",
    "    X_arr = np.asarray(X_current, dtype=float)\n",
    "    if rng is None:\n",
    "        Z = np.random.normal(size=X_arr.shape)\n",
    "    else:\n",
    "        Z = rng.normal(size=X_arr.shape)\n",
    "    sqrt_dt = np.sqrt(Delta_t)\n",
    "    X_clip = np.maximum(X_arr, 0.0)\n",
    "    drift = alpha * (mk_scalar - X_arr) * Delta_t\n",
    "    diffusion = sigma * np.sqrt(X_clip) * Z * sqrt_dt\n",
    "    return np.abs(X_arr + drift + diffusion)\n",
    "\n",
    "def next_I_B(I_current, B):\n",
    "    # reuse your vectorized logic\n",
    "    if np.isscalar(B):\n",
    "        if B >= 0:\n",
    "            return I_current + eta_B * B * Delta_t_B\n",
    "        else:\n",
    "            return I_current + B * Delta_t_B / eta_B\n",
    "    else:\n",
    "        B_arr = np.asarray(B, dtype=float)\n",
    "        I_arr = np.asarray(I_current, dtype=float)\n",
    "        result = np.empty_like(B_arr)\n",
    "        mask = B_arr >= 0\n",
    "        result[mask] = I_arr[mask] + eta_B * B_arr[mask] * Delta_t_B\n",
    "        result[~mask] = I_arr[~mask] + B_arr[~mask] * Delta_t_B / eta_B\n",
    "        return result\n",
    "\n",
    "def pilot_stats_X(\n",
    "    mk_profile: np.ndarray,\n",
    "    alpha: float,\n",
    "    sigma: float,\n",
    "    Delta_t: float,\n",
    "    n_steps: int,\n",
    "    n_paths: int,\n",
    "    X0: float | None = None,\n",
    "    seed: int = 123,\n",
    "    *,\n",
    "    rng: np.random.Generator | None = None,\n",
    " ):\n",
    "    # Pilot uses its own RNG by default for reproducibility\n",
    "    rng = np.random.default_rng(seed) if rng is None else rng\n",
    "    X = np.zeros((n_paths, n_steps + 1), dtype=float)\n",
    "    if X0 is None:\n",
    "        X[:, 0] = float(mk_profile[0])\n",
    "    else:\n",
    "        X[:, 0] = float(X0)\n",
    "    for k in range(n_steps):\n",
    "        Z = rng.normal(size=n_paths)\n",
    "        Xk = X[:, k]\n",
    "        X_clip = np.maximum(Xk, 0.0)\n",
    "        drift = alpha * (mk_profile[k] - Xk) * Delta_t\n",
    "        diffusion = sigma * np.sqrt(X_clip) * Z * np.sqrt(Delta_t)\n",
    "        X[:, k + 1] = np.abs(Xk + drift + diffusion)\n",
    "    mean_k = X[:, :n_steps].mean(axis=0)\n",
    "    std_k = X[:, :n_steps].std(axis=0, ddof=1)\n",
    "    return mean_k, std_k\n",
    "\n",
    "EX_k, SD_k = pilot_stats_X(mk_B, alpha_B, sigma_B, Delta_t_B, n_steps_B, MC_PATHS_PILOT)\n",
    "Xmin_k = np.maximum(EX_k - 2.0 * SD_k, 0.0)\n",
    "Xmax_k = EX_k + 2.0 * SD_k\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(t_hours_B, EX_k, label=\"Pilot E[X_k]\")\n",
    "plt.fill_between(t_hours_B, Xmin_k, Xmax_k, alpha=0.25, label=\"E[X_k] ± 2 SD\")\n",
    "plt.plot(t_hours_B, Mk_B, \"--\", label=\"M_k\")\n",
    "plt.title(\"Pilot stats for adaptive designs (IV-B)\")\n",
    "plt.xlabel(\"Hour of day\")\n",
    "plt.ylabel(\"MW\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: IV-B RMC training (adaptive designs per k)\n",
    "def sample_design_lhs_k(Nloc: int, k: int, seed: int = 42):\n",
    "    # X bounds depend on k (paper: adaptive D_k)\n",
    "    x_lo = float(Xmin_k[k])\n",
    "    x_hi = float(Xmax_k[k])\n",
    "    # Safety for degenerate ranges\n",
    "    if not np.isfinite(x_lo) or not np.isfinite(x_hi) or x_hi <= x_lo:\n",
    "        x_lo, x_hi = 0.0, max(1.0, float(mk_B[k]) + 1.0)\n",
    "    lhs = latin_hypercube(Nloc, 2, seed=seed + k)\n",
    "    return scale_lhs(lhs, [x_lo, 0.0], [x_hi, Icap_B])\n",
    "\n",
    "def train_rmc_nonstationary(\n",
    "    mk_profile: np.ndarray,\n",
    "    Mk_profile: np.ndarray,\n",
    "    *,\n",
    "    Nloc: int,\n",
    "    Nrep: int,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"RMC backward loop for IV-B.\n",
    "\n",
    "    Reproducibility: we use a per-time-step RNG (seeded from `seed` and `t`) so that\n",
    "    the replicate noises are independent but deterministic across runs.\n",
    "    \"\"\"\n",
    "    control_gps_B = [None] * n_steps_B\n",
    "    value_gps_B = [None] * n_steps_B\n",
    "    opt_options_local = {'ftol': 1e-9, 'maxiter': 200}\n",
    "    for t in range(n_steps_B - 1, -1, -1):\n",
    "        print(f\"IV-B backward step t={t}/{n_steps_B-1}\")\n",
    "        X_I_design = sample_design_lhs_k(Nloc, t, seed=seed)\n",
    "        X_t_loc = X_I_design[:, 0]\n",
    "        I_t_loc = X_I_design[:, 1]\n",
    "        X_current = np.repeat(X_t_loc, Nrep)\n",
    "        I_current = np.repeat(I_t_loc, Nrep)\n",
    "\n",
    "        # Per-step RNG: deterministic across runs, independent across t\n",
    "        rng_t = np.random.default_rng(seed + t)\n",
    "\n",
    "        # one-step forward using time-varying m_t and state-dependent vol (Eq. 19)\n",
    "        X_next = next_X_nonstationary(\n",
    "        X_current,\n",
    "        float(mk_profile[t]),\n",
    "        alpha_B,\n",
    "        sigma_B,\n",
    "        Delta_t_B,\n",
    "        rng=rng_t,\n",
    "        )\n",
    "\n",
    "        B_opt_per_loc = np.zeros(Nloc, dtype=float)\n",
    "        for i in range(Nloc):\n",
    "            start = i * Nrep\n",
    "            end = start + Nrep\n",
    "            X_cur_rep = X_current[start:end]\n",
    "            X_next_rep = X_next[start:end]\n",
    "            I_cur_rep = I_current[start:end]\n",
    "            lower_i, upper_i = get_bounds_B(float(I_t_loc[i]))\n",
    "            if lower_i >= upper_i:\n",
    "                B_opt_per_loc[i] = 0.5 * (lower_i + upper_i)\n",
    "                continue\n",
    "\n",
    "            Mk_t = float(Mk_profile[t])\n",
    "            def obj_scalar(b_array):\n",
    "                b = float(np.atleast_1d(b_array)[0])\n",
    "                immediate = (X_cur_rep - b - Mk_t) ** 2\n",
    "                I_next_rep = next_I_B(I_cur_rep, b)\n",
    "                if t == n_steps_B - 1:\n",
    "                    cont_rep = terminal_penalty_array_B(I_next_rep)\n",
    "                else:\n",
    "                    cont_rep = value_gps_B[t + 1].predict(np.column_stack((X_next_rep, I_next_rep))).flatten()\n",
    "                return float(np.mean(immediate + cont_rep))\n",
    "\n",
    "            x0 = np.array([0.5 * (lower_i + upper_i)])\n",
    "            res = minimize(obj_scalar, x0=x0, method='L-BFGS-B', options=opt_options_local)\n",
    "            b_hat = float(res.x[0])\n",
    "            B_opt_per_loc[i] = float(np.clip(b_hat, lower_i, upper_i))\n",
    "\n",
    "        B_pathwise = np.repeat(B_opt_per_loc, Nrep)\n",
    "        I_next_all = next_I_B(I_current, B_pathwise)\n",
    "        loss_all = (X_current - B_pathwise - float(Mk_profile[t])) ** 2\n",
    "        if t == n_steps_B - 1:\n",
    "            cont_all = terminal_penalty_array_B(I_next_all)\n",
    "        else:\n",
    "            cont_all = value_gps_B[t + 1].predict(np.column_stack((X_next, I_next_all))).flatten()\n",
    "        v_all = loss_all + cont_all\n",
    "        B_avg = B_pathwise.reshape(Nloc, Nrep).mean(axis=1)\n",
    "        v_avg = v_all.reshape(Nloc, Nrep).mean(axis=1)\n",
    "\n",
    "        control_kernel = Matern(length_scale=1.0, nu=1.5)\n",
    "        control_gp = GaussianProcessRegressor(kernel=control_kernel, n_restarts_optimizer=5, random_state=seed)\n",
    "        control_gp.fit(X_I_design, B_avg)\n",
    "        control_gps_B[t] = control_gp\n",
    "\n",
    "        value_kernel = Matern(length_scale=[1.0, 1.0], nu=2.5)\n",
    "        value_gp = GaussianProcessRegressor(kernel=value_kernel, n_restarts_optimizer=5, random_state=seed)\n",
    "        value_gp.fit(X_I_design, v_avg)\n",
    "        value_gps_B[t] = value_gp\n",
    "    return control_gps_B, value_gps_B\n",
    "\n",
    "# Train (warning: can take time). You can reduce Nloc_B/Nrep_B for a quick run.\n",
    "TRAIN_IVB = True\n",
    "if TRAIN_IVB:\n",
    "    control_gps_B, value_gps_B = train_rmc_nonstationary(mk_B, Mk_B, Nloc=Nloc_B, Nrep=Nrep_B)\n",
    "    print(\"IV-B training complete\")\n",
    "else:\n",
    "    print(\"Set TRAIN_IVB=True to train the IV-B policy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5045bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: IV-B evaluation + Figure-5-style confidence bands\n",
    "def simulate_path_ivb(\n",
    "    control_gps_B,\n",
    "    mk_profile: np.ndarray,\n",
    "    Mk_profile: np.ndarray,\n",
    "    *,\n",
    "    X_start: float | None = None,\n",
    "    I_start: float = I0_B,\n",
    "    seed: int | None = None,\n",
    "):\n",
    "    rng = np.random.default_rng(seed) if seed is not None else np.random.default_rng()\n",
    "    if X_start is None:\n",
    "        X = float(mk_profile[0])\n",
    "    else:\n",
    "        X = float(X_start)\n",
    "    I = float(I_start)\n",
    "    X_path = [X]\n",
    "    I_path = [I]\n",
    "    B_path = []\n",
    "    O_path = []\n",
    "    for k in range(n_steps_B):\n",
    "        B_raw = float(control_gps_B[k].predict([[X, I]])[0])\n",
    "        lower, upper = get_bounds_B(I)\n",
    "        B = float(np.clip(B_raw, lower, upper))\n",
    "        O = X - B\n",
    "        B_path.append(B)\n",
    "        O_path.append(O)\n",
    "        X = float(next_X_nonstationary(X, float(mk_profile[k]), alpha_B, sigma_B, Delta_t_B, rng=rng))\n",
    "        I = float(next_I_B(I, B))\n",
    "        I = float(np.clip(I, SoC_min_B * Icap_B, SoC_max_B * Icap_B))\n",
    "        X_path.append(X)\n",
    "        I_path.append(I)\n",
    "    return np.array(X_path), np.array(I_path), np.array(B_path), np.array(O_path)\n",
    "\n",
    "def simulate_path_greedy_ivb(\n",
    "    mk_profile: np.ndarray,\n",
    "    Mk_profile: np.ndarray,\n",
    "    *,\n",
    "    X_start: float | None = None,\n",
    "    I_start: float = I0_B,\n",
    "    seed: int | None = None,\n",
    "):\n",
    "    # Greedy = myopic firming: B ~= X - M_k with SoC feasibility clipping\n",
    "    rng = np.random.default_rng(seed) if seed is not None else np.random.default_rng()\n",
    "    X = float(mk_profile[0] if X_start is None else X_start)\n",
    "    I = float(I_start)\n",
    "    X_path = [X]\n",
    "    I_path = [I]\n",
    "    B_path = []\n",
    "    O_path = []\n",
    "    for k in range(n_steps_B):\n",
    "        B_raw = X - float(Mk_profile[k])\n",
    "        lower, upper = get_bounds_B(I)\n",
    "        B = float(np.clip(B_raw, lower, upper))\n",
    "        O = X - B\n",
    "        B_path.append(B)\n",
    "        O_path.append(O)\n",
    "        X = float(next_X_nonstationary(X, float(mk_profile[k]), alpha_B, sigma_B, Delta_t_B, rng=rng))\n",
    "        I = float(next_I_B(I, B))\n",
    "        I = float(np.clip(I, SoC_min_B * Icap_B, SoC_max_B * Icap_B))\n",
    "        X_path.append(X)\n",
    "        I_path.append(I)\n",
    "    return np.array(X_path), np.array(I_path), np.array(B_path), np.array(O_path)\n",
    "\n",
    "def loss_L2_ivb(O_path: np.ndarray, Mk_profile: np.ndarray, I_T: float) -> float:\n",
    "    return float(np.sum((O_path - Mk_profile) ** 2) + terminal_penalty_B(float(I_T)))\n",
    "\n",
    "def confidence_bands(paths: np.ndarray, q_lo=0.025, q_hi=0.975):\n",
    "    lo = np.quantile(paths, q_lo, axis=0)\n",
    "    hi = np.quantile(paths, q_hi, axis=0)\n",
    "    mid = np.quantile(paths, 0.5, axis=0)\n",
    "    return lo, mid, hi\n",
    "\n",
    "PLOT_IVB = True\n",
    "if PLOT_IVB:\n",
    "    if 'control_gps_B' not in globals():\n",
    "        raise RuntimeError(\"Train first: set TRAIN_IVB=True in Cell 6\")\n",
    "\n",
    "    M = MC_PATHS_BANDS\n",
    "    X_paths = np.zeros((M, n_steps_B), dtype=float)\n",
    "    O_paths = np.zeros((M, n_steps_B), dtype=float)\n",
    "    Og_paths = np.zeros((M, n_steps_B), dtype=float)\n",
    "    losses_opt = np.zeros(M)\n",
    "    losses_greedy = np.zeros(M)\n",
    "\n",
    "    for m in range(M):\n",
    "        X_p, I_p, _, O_p = simulate_path_ivb(control_gps_B, mk_B, Mk_B, seed=10_000 + m)\n",
    "        Xg_p, Ig_p, _, Og_p = simulate_path_greedy_ivb(mk_B, Mk_B, seed=20_000 + m)\n",
    "        X_paths[m, :] = X_p[:-1]\n",
    "        O_paths[m, :] = O_p\n",
    "        Og_paths[m, :] = Og_p\n",
    "        losses_opt[m] = loss_L2_ivb(O_p, Mk_B, I_p[-1])\n",
    "        losses_greedy[m] = loss_L2_ivb(Og_p, Mk_B, Ig_p[-1])\n",
    "\n",
    "    impr = 100.0 * (np.mean(losses_greedy) - np.mean(losses_opt)) / np.mean(losses_greedy)\n",
    "    print(f\"Mean L2 loss (opt):    {np.mean(losses_opt):.2f}\")\n",
    "    print(f\"Mean L2 loss (greedy): {np.mean(losses_greedy):.2f}\")\n",
    "    print(f\"% improvement: {impr:.1f}%\")\n",
    "\n",
    "    x_lo, x_mid, x_hi = confidence_bands(X_paths)\n",
    "    o_lo, o_mid, o_hi = confidence_bands(O_paths)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.fill_between(t_hours_B, x_lo, x_hi, color='gold', alpha=0.35, label='95% CI of X_k')\n",
    "    plt.fill_between(t_hours_B, o_lo, o_hi, color='red', alpha=0.25, label='95% CI of O_k (opt)')\n",
    "    plt.plot(t_hours_B, Mk_B, color='black', linewidth=2, label='M_k target')\n",
    "    plt.title(f\"IV-B firming bands for {DAY_TO_RUN} (mode={TARGET_MODE}), improvement={impr:.1f}%\")\n",
    "    plt.xlabel(\"Hour of day\")\n",
    "    plt.ylabel(\"MW\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Set PLOT_IVB=True to generate Figure-5-style bands (requires trained control_gps_B).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Fig.4-style single-trajectory plot (same X_k, compare Greedy(L1) vs Opt(L2))\n",
    "PLOT_TRAJ_IVB = True\n",
    "TRAJ_SEED = 12345\n",
    "X0_MODE = \"mk0\"   # \"mk0\" or \"value\"\n",
    "X0_VALUE = None   # used if X0_MODE == \"value\"\n",
    "\n",
    "def simulate_X_path_only(mk_profile: np.ndarray, *, seed: int, X_start: float | None = None) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = np.zeros(n_steps_B + 1, dtype=float)\n",
    "    X[0] = float(mk_profile[0] if X_start is None else X_start)\n",
    "    for k in range(n_steps_B):\n",
    "        Z = float(rng.normal())\n",
    "        Xk = float(X[k])\n",
    "        drift = alpha_B * (float(mk_profile[k]) - Xk) * Delta_t_B\n",
    "        diffusion = sigma_B * np.sqrt(max(Xk, 0.0)) * Z * np.sqrt(Delta_t_B)\n",
    "        X[k + 1] = abs(Xk + drift + diffusion)\n",
    "    return X\n",
    "\n",
    "def apply_policy_on_X(X_path: np.ndarray, Mk_profile: np.ndarray, *, policy: str, control_gps=None, I_start: float = I0_B):\n",
    "    I = float(I_start)\n",
    "    I_path = np.zeros(n_steps_B + 1, dtype=float)\n",
    "    B_path = np.zeros(n_steps_B, dtype=float)\n",
    "    O_path = np.zeros(n_steps_B, dtype=float)\n",
    "    I_path[0] = I\n",
    "    for k in range(n_steps_B):\n",
    "        Xk = float(X_path[k])\n",
    "        if policy == \"greedy\":\n",
    "            B_raw = Xk - float(Mk_profile[k])\n",
    "        elif policy == \"opt\":\n",
    "            if control_gps is None:\n",
    "                raise RuntimeError(\"control_gps is required for policy='opt'\")\n",
    "            B_raw = float(control_gps[k].predict([[Xk, I]])[0])\n",
    "        else:\n",
    "            raise ValueError(\"policy must be 'greedy' or 'opt'\")\n",
    "\n",
    "        lower, upper = get_bounds_B(I)\n",
    "        B = float(np.clip(B_raw, lower, upper))\n",
    "        O = Xk - B\n",
    "        B_path[k] = B\n",
    "        O_path[k] = O\n",
    "        I = float(next_I_B(I, B))\n",
    "        I = float(np.clip(I, SoC_min_B * Icap_B, SoC_max_B * Icap_B))\n",
    "        I_path[k + 1] = I\n",
    "    return I_path, B_path, O_path\n",
    "\n",
    "if PLOT_TRAJ_IVB:\n",
    "    X0 = None if X0_MODE == \"mk0\" else float(X0_VALUE)\n",
    "    X_path = simulate_X_path_only(mk_B, seed=TRAJ_SEED, X_start=X0)\n",
    "\n",
    "    # Greedy (proxy for paper's L1 baseline in IV-B comparisons)\n",
    "    I_g, B_g, O_g = apply_policy_on_X(X_path, Mk_B, policy=\"greedy\")\n",
    "\n",
    "    have_opt = \"control_gps_B\" in globals()\n",
    "    if have_opt:\n",
    "        I_o, B_o, O_o = apply_policy_on_X(X_path, Mk_B, policy=\"opt\", control_gps=control_gps_B)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "    axes[0].plot(t_hours_B, X_path[:-1], label=r\"$X_k$\")\n",
    "    axes[0].set_ylabel(\"MW\")\n",
    "    axes[0].set_title(f\"Single trajectory on {DAY_TO_RUN} (seed={TRAJ_SEED}, mode={TARGET_MODE})\")\n",
    "\n",
    "    axes[1].plot(t_hours_B, I_g[:-1], label=\"Greedy (L1)\")\n",
    "    if have_opt:\n",
    "        axes[1].plot(t_hours_B, I_o[:-1], label=\"Opt (L2)\")\n",
    "    axes[1].set_ylabel(\"MWh\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    axes[2].plot(t_hours_B, O_g, label=\"Greedy (L1)\")\n",
    "    if have_opt:\n",
    "        axes[2].plot(t_hours_B, O_o, label=\"Opt (L2)\")\n",
    "    axes[2].plot(t_hours_B, Mk_B, color=\"black\", linewidth=1.5, label=r\"$M_k$\")\n",
    "    axes[2].set_ylabel(\"MW\")\n",
    "    axes[2].set_xlabel(\"Time (hours)\")\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if have_opt:\n",
    "        loss_opt = loss_L2_ivb(O_o, Mk_B, I_o[-1])\n",
    "        loss_greedy = loss_L2_ivb(O_g, Mk_B, I_g[-1])\n",
    "        impr = 100.0 * (loss_greedy - loss_opt) / loss_greedy\n",
    "        print(f\"Single-path L2 loss opt:    {loss_opt:.2f}\")\n",
    "        print(f\"Single-path L2 loss greedy: {loss_greedy:.2f}\")\n",
    "        print(f\"Single-path % improvement:  {impr:.1f}%\")\n",
    "    else:\n",
    "        print(\"Opt (L2) curve not shown: train first (set TRAIN_IVB=True in Cell 6 and run it).\")\n",
    "else:\n",
    "    print(\"Set PLOT_TRAJ_IVB=True to generate a Fig.4-style single-trajectory plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
